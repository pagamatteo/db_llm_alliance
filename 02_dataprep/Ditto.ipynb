{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP/SoNaDtGsiwdU27pE9meF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5e7969f59f5746daa2ed74c09268f94e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b383c3de3c74d9c8c98e9561ca3d079","IPY_MODEL_32b8af14ce7e4a30a976b1fe413dd388","IPY_MODEL_37d2ec36c67249b5ad43349cc7f5a130"],"layout":"IPY_MODEL_4e659bfdba154fd99fa20b85130009b3"}},"4b383c3de3c74d9c8c98e9561ca3d079":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad860d64d433496994eb8e04136ac30b","placeholder":"​","style":"IPY_MODEL_2b6ac2e3ccf24eef8d1245350a8c42b3","value":"tokenizer_config.json: 100%"}},"32b8af14ce7e4a30a976b1fe413dd388":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_507153608f0248c1beef89d551469e75","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4825b967604c428ead396a5f354a484b","value":25}},"37d2ec36c67249b5ad43349cc7f5a130":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_607195a85ae34c169cd4917b9374709f","placeholder":"​","style":"IPY_MODEL_0e1396ebab0d45a89f7ead8ba4a63173","value":" 25.0/25.0 [00:00&lt;00:00, 475B/s]"}},"4e659bfdba154fd99fa20b85130009b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad860d64d433496994eb8e04136ac30b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b6ac2e3ccf24eef8d1245350a8c42b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"507153608f0248c1beef89d551469e75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4825b967604c428ead396a5f354a484b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"607195a85ae34c169cd4917b9374709f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e1396ebab0d45a89f7ead8ba4a63173":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0a10a02037545f0beeb36f6a2d52a40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e711ec4c06b467caaed45be969c6df7","IPY_MODEL_60357971436b4a6f956ded7b2d1c8606","IPY_MODEL_fc6c623ca0b44310bdce0ae5855b9b40"],"layout":"IPY_MODEL_b2c33b8464ed4eaf86395e229714e870"}},"4e711ec4c06b467caaed45be969c6df7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c896e80432d74c1ca509aaf43c23a906","placeholder":"​","style":"IPY_MODEL_cb1089a94f8c4882b9826450e3c9fb98","value":"config.json: 100%"}},"60357971436b4a6f956ded7b2d1c8606":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17c4b6bc8dd443afbe9c9544b4115e87","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31a39265997643159e46153542ecbfac","value":481}},"fc6c623ca0b44310bdce0ae5855b9b40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bff397b6a4574bd08602f0f98ab674c6","placeholder":"​","style":"IPY_MODEL_61249fef881e457e9956446e7e631921","value":" 481/481 [00:00&lt;00:00, 8.79kB/s]"}},"b2c33b8464ed4eaf86395e229714e870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c896e80432d74c1ca509aaf43c23a906":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb1089a94f8c4882b9826450e3c9fb98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17c4b6bc8dd443afbe9c9544b4115e87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31a39265997643159e46153542ecbfac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bff397b6a4574bd08602f0f98ab674c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61249fef881e457e9956446e7e631921":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"836c6d9e978a4937848ec65f94428cdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b845879cef174924a9dd69fecc159a8d","IPY_MODEL_d885f524b0dd49bd9344e3eb530c3e8c","IPY_MODEL_67eb34c980e14b909a2acf90440162a9"],"layout":"IPY_MODEL_ccce76cf7d484b72ab90c7f9084c21fc"}},"b845879cef174924a9dd69fecc159a8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e8f940731f74834b7e5a843df14e40a","placeholder":"​","style":"IPY_MODEL_7baf31fe312c41f1a0207756c761defa","value":"vocab.json: 100%"}},"d885f524b0dd49bd9344e3eb530c3e8c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_772ed413826d42889de6b21d845197e3","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8f04503ba0124f81a90a7502f7f0d16a","value":898823}},"67eb34c980e14b909a2acf90440162a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a9af53757354c0da7867cd46a2558f5","placeholder":"​","style":"IPY_MODEL_a02a46b9054b4f04aa2994b0ae505fd7","value":" 899k/899k [00:00&lt;00:00, 1.04MB/s]"}},"ccce76cf7d484b72ab90c7f9084c21fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e8f940731f74834b7e5a843df14e40a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7baf31fe312c41f1a0207756c761defa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"772ed413826d42889de6b21d845197e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f04503ba0124f81a90a7502f7f0d16a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a9af53757354c0da7867cd46a2558f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a02a46b9054b4f04aa2994b0ae505fd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae5439e19ef246a0a86ad23ab70f02c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad1ba7c81ee5441ebd3041859f2e1324","IPY_MODEL_8657afd576864fd8ab62657304c6417e","IPY_MODEL_38f8ea4b335d4343a49ad014550030ed"],"layout":"IPY_MODEL_c935db4ad072478f8e29adf25f595e36"}},"ad1ba7c81ee5441ebd3041859f2e1324":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec2bb75474c6427fa06bb271517f71dc","placeholder":"​","style":"IPY_MODEL_95fdb6969bf54bf3a8c0e65b3d2b513c","value":"merges.txt: 100%"}},"8657afd576864fd8ab62657304c6417e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59cad8b171d94f8f84ad1b008bdd2c72","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e61f8d76b9e2436398f17d572671a2e3","value":456318}},"38f8ea4b335d4343a49ad014550030ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b53f241dcf23469086b1401f0f3acbd4","placeholder":"​","style":"IPY_MODEL_a0ea06079dea4a59ab2e20f27ec9edce","value":" 456k/456k [00:00&lt;00:00, 9.22MB/s]"}},"c935db4ad072478f8e29adf25f595e36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec2bb75474c6427fa06bb271517f71dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95fdb6969bf54bf3a8c0e65b3d2b513c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59cad8b171d94f8f84ad1b008bdd2c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e61f8d76b9e2436398f17d572671a2e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b53f241dcf23469086b1401f0f3acbd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ea06079dea4a59ab2e20f27ec9edce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a492b079d703422887221481d05835a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cc59c75786a437f9ede911ae9665176","IPY_MODEL_8f5a7327f4b845989fe1444a74214253","IPY_MODEL_f94ab14be5c94f8c8814234bb8150855"],"layout":"IPY_MODEL_8243793df3d54aa0b0f07ceea5d6412d"}},"3cc59c75786a437f9ede911ae9665176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bcb4b2f29b34d2ca3bcea957192f848","placeholder":"​","style":"IPY_MODEL_590849c5e4b64f53841a74f826bc45e7","value":"tokenizer.json: 100%"}},"8f5a7327f4b845989fe1444a74214253":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ba881b4d82e48cf86f87ec8bc631d12","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd3e88f23cf6434fa31356ac59d216ad","value":1355863}},"f94ab14be5c94f8c8814234bb8150855":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c81b1cc153314e72babd5a75353d8c27","placeholder":"​","style":"IPY_MODEL_0ddbb3f175104daf83cca51cf8035fec","value":" 1.36M/1.36M [00:00&lt;00:00, 6.21MB/s]"}},"8243793df3d54aa0b0f07ceea5d6412d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bcb4b2f29b34d2ca3bcea957192f848":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"590849c5e4b64f53841a74f826bc45e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ba881b4d82e48cf86f87ec8bc631d12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd3e88f23cf6434fa31356ac59d216ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c81b1cc153314e72babd5a75353d8c27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ddbb3f175104daf83cca51cf8035fec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29426945a33840a28be61c5d8503d049":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a614de527d6a412da4d0435ad5183060","IPY_MODEL_eda78502c19949768438592b02e2cea9","IPY_MODEL_3c581cecb60741548be61d1180a2af2c"],"layout":"IPY_MODEL_4796990006a24eb4a6599e40de17771b"}},"a614de527d6a412da4d0435ad5183060":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13764a4fb9794f2dbf7dcbbb774ec26d","placeholder":"​","style":"IPY_MODEL_6f7eed13ab2645eaa35956da2bec9515","value":"model.safetensors: 100%"}},"eda78502c19949768438592b02e2cea9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b3fa83df0f49129a8546068254237c","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb670a6f14f44e21927d9fef2964ded3","value":498818054}},"3c581cecb60741548be61d1180a2af2c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7811fa6f385247c48b1cc9958a1d8f0f","placeholder":"​","style":"IPY_MODEL_4a136676a6194e5ea673ecf303e86cea","value":" 499M/499M [00:05&lt;00:00, 76.4MB/s]"}},"4796990006a24eb4a6599e40de17771b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13764a4fb9794f2dbf7dcbbb774ec26d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f7eed13ab2645eaa35956da2bec9515":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9b3fa83df0f49129a8546068254237c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb670a6f14f44e21927d9fef2964ded3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7811fa6f385247c48b1cc9958a1d8f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a136676a6194e5ea673ecf303e86cea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Environment preparation"],"metadata":{"id":"pG5tmLPcSx1-"}},{"cell_type":"markdown","source":["## Libraries"],"metadata":{"id":"i-fmt-ZHgjl2"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"B_Mx3Ou9Pb6q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725696833898,"user_tz":-120,"elapsed":16155,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}},"outputId":"8ec47cf4-8393-438c-e373-81dbdcc812ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Collecting jsonlines\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n","Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-4.0.0\n"]}],"source":["!pip install transformers\n","!pip install jsonlines"]},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import sklearn.metrics as metrics\n","import json\n","import csv\n","from torch.utils import data\n","from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from collections import Counter\n","from nltk.corpus import stopwords\n","import spacy\n","import jsonlines\n","import re\n","import time\n","import sklearn\n","from tqdm import tqdm\n","from scipy.special import softmax\n"],"metadata":{"id":"dGChVOg4PrjK","executionInfo":{"status":"ok","timestamp":1725696850500,"user_tz":-120,"elapsed":16604,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!python -m spacy download en_core_web_lg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3tDp0oZgVLd","executionInfo":{"status":"ok","timestamp":1725696895012,"user_tz":-120,"elapsed":44514,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}},"outputId":"807d94c0-ccb3-4bc5-ba51-0bba70ed0daf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-lg==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.8.0)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.19.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-3.7.1\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_lg')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1V3_lp3VifL","executionInfo":{"status":"ok","timestamp":1725696895012,"user_tz":-120,"elapsed":7,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}},"outputId":"bfac98db-1af9-41f7-cc12-72a33c3a3668"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Sample data"],"metadata":{"id":"eW9SEvBdgc8-"}},{"cell_type":"code","source":["url = f\"https://raw.githubusercontent.com/megagonlabs/ditto/master/data/er_magellan/Structured/Beer/train.txt\"\n","!wget --no-cache --backups=1 {url}\n","url = f\"https://raw.githubusercontent.com/megagonlabs/ditto/master/data/er_magellan/Structured/Beer/valid.txt\"\n","!wget --no-cache --backups=1 {url}\n","url = f\"https://raw.githubusercontent.com/megagonlabs/ditto/master/data/er_magellan/Structured/Beer/test.txt\"\n","!wget --no-cache --backups=1 {url}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPq8iH5fTdjx","executionInfo":{"status":"ok","timestamp":1725696896141,"user_tz":-120,"elapsed":1135,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}},"outputId":"57d27dbe-78bf-47f7-8a40-067e8146326c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-09-07 08:14:53--  https://raw.githubusercontent.com/megagonlabs/ditto/master/data/er_magellan/Structured/Beer/train.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84402 (82K) [text/plain]\n","Failed to rename train.txt to train.txt.1: (2) No such file or directory\n","Saving to: ‘train.txt’\n","\n","train.txt           100%[===================>]  82.42K  --.-KB/s    in 0.002s  \n","\n","2024-09-07 08:14:54 (52.8 MB/s) - ‘train.txt’ saved [84402/84402]\n","\n","--2024-09-07 08:14:54--  https://raw.githubusercontent.com/megagonlabs/ditto/master/data/er_magellan/Structured/Beer/valid.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28547 (28K) [text/plain]\n","Failed to rename valid.txt to valid.txt.1: (2) No such file or directory\n","Saving to: ‘valid.txt’\n","\n","valid.txt           100%[===================>]  27.88K  --.-KB/s    in 0s      \n","\n","2024-09-07 08:14:54 (159 MB/s) - ‘valid.txt’ saved [28547/28547]\n","\n","--2024-09-07 08:14:54--  https://raw.githubusercontent.com/megagonlabs/ditto/master/data/er_magellan/Structured/Beer/test.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28611 (28K) [text/plain]\n","Failed to rename test.txt to test.txt.1: (2) No such file or directory\n","Saving to: ‘test.txt’\n","\n","test.txt            100%[===================>]  27.94K  --.-KB/s    in 0.001s  \n","\n","2024-09-07 08:14:55 (54.1 MB/s) - ‘test.txt’ saved [28611/28611]\n","\n"]}]},{"cell_type":"markdown","source":["# Data preparation"],"metadata":{"id":"pWJB7xopcRz0"}},{"cell_type":"markdown","source":["## Augmenter"],"metadata":{"id":"dk8iq_x3eHiT"}},{"cell_type":"code","source":["class Augmenter:\n","    \"\"\"Data augmentation operator.\n","\n","    Support both span and attribute level augmentation operators.\n","    \"\"\"\n","    def __init__(self):\n","        pass\n","\n","    def augment(self, tokens, labels, op='del'):\n","        \"\"\" Performs data augmentation on a sequence of tokens\n","\n","        The supported ops:\n","           ['del', 'drop_col',\n","            'append_col', 'drop_token',\n","            'drop_len',\n","            'drop_sym',\n","            'drop_same',\n","            'swap',\n","            'ins',\n","            'all']\n","\n","        Args:\n","            tokens (list of strings): the input tokens\n","            labels (list of strings): the labels of the tokens\n","            op (str, optional): a string encoding of the operator to be applied\n","\n","        Returns:\n","            list of strings: the augmented tokens\n","            list of strings: the augmented labels\n","        \"\"\"\n","        if 'del' in op:\n","            # insert padding to keep the length consistent\n","            # span_len = random.randint(1, 3)\n","            span_len = random.randint(1, 2)\n","            pos1, pos2 = self.sample_span(tokens, labels, span_len=span_len)\n","            if pos1 < 0:\n","                return tokens, labels\n","            new_tokens = tokens[:pos1] + tokens[pos2+1:]\n","            new_labels = tokens[:pos1] + labels[pos2+1:]\n","        elif 'swap' in op:\n","            span_len = random.randint(2, 4)\n","            pos1, pos2 = self.sample_span(tokens, labels, span_len=span_len)\n","            if pos1 < 0:\n","                return tokens, labels\n","            sub_arr = tokens[pos1:pos2+1]\n","            random.shuffle(sub_arr)\n","            new_tokens = tokens[:pos1] + sub_arr + tokens[pos2+1:]\n","            new_labels = tokens[:pos1] + ['O'] * (pos2 - pos1 + 1) + labels[pos2+1:]\n","        elif 'drop_len' in op:\n","            # drop tokens below a certain length\n","            all_lens = [len(token) for token, label in \\\n","                    zip(tokens, labels) if label == 'O']\n","            if len(all_lens) == 0:\n","                return tokens, labels\n","            target_lens = random.choices(all_lens, k=1)\n","            new_tokens = []\n","            new_labels = []\n","\n","            for token, label in zip(tokens, labels):\n","                if label != 'O' or len(token) not in target_lens:\n","                    new_tokens.append(token)\n","                    new_labels.append(label)\n","            return new_tokens, new_labels\n","        elif 'drop_sym' in op:\n","            def drop_sym(token):\n","                return ''.join([ch if ch.isalnum() else ' ' for ch in token])\n","            dropped_tokens = [drop_sym(token) for token in tokens]\n","            new_tokens = []\n","            new_labels = []\n","            for token, d_token, label in zip(tokens, dropped_tokens, labels):\n","                if random.randint(0, 4) != 0 or label != 'O':\n","                    new_tokens.append(token)\n","                    new_labels.append(label)\n","                else:\n","                    if d_token != '':\n","                        new_tokens.append(d_token)\n","                        new_labels.append(label)\n","        elif 'drop_same' in op:\n","            left_token = set([])\n","            right_token = set([])\n","            left = True\n","            for token, label in zip(tokens, labels):\n","                if label == 'O':\n","                    token = token.lower()\n","                    if left:\n","                        left_token.add(token)\n","                    else:\n","                        right_token.add(token)\n","                if token == '[SEP]':\n","                    left = False\n","\n","            same = left_token & right_token\n","            targets = random.choices(list(same), k=1)\n","            new_tokens, new_labels = [], []\n","            for token, label in zip(tokens, labels):\n","                if token.lower() not in targets or label != 'O':\n","                    new_tokens.append(token)\n","                    new_labels.append(label)\n","            return new_tokens, new_labels\n","        elif 'drop_token' in op:\n","            new_tokens, new_labels = [], []\n","            for token, label in zip(tokens, labels):\n","                if label != 'O' or random.randint(0, 4) != 0:\n","                    new_tokens.append(token)\n","                    new_labels.append(label)\n","            return new_tokens, new_labels\n","        elif 'ins' in op:\n","            pos = self.sample_position(tokens, labels)\n","            symbol = random.choice('-*.,#&')\n","            new_tokens = tokens[:pos] + [symbol] + tokens[pos:]\n","            new_labels = labels[:pos] + ['O'] + labels[pos:]\n","            return new_tokens, new_labels\n","        elif 'append_col' in op:\n","            col_starts = [i for i in range(len(tokens)) if tokens[i] == 'COL']\n","            col_ends = [0] * len(col_starts)\n","            col_lens = [0] * len(col_starts)\n","            for i, pos in enumerate(col_starts):\n","                if i == len(col_starts) - 1:\n","                    col_lens[i] = len(tokens) - pos\n","                    col_ends[i] = len(tokens) - 1\n","                else:\n","                    col_lens[i] = col_starts[i + 1] - pos\n","                    col_ends[i] = col_starts[i + 1] - 1\n","\n","                if tokens[col_ends[i]] == '[SEP]':\n","                    col_ends[i] -= 1\n","                    col_lens[i] -= 1\n","                    break\n","            candidates = [i for i, le in enumerate(col_lens) if le > 0]\n","            if len(candidates) >= 2:\n","                idx1, idx2 = random.sample(candidates,k=2)\n","                start1, end1 = col_starts[idx1], col_ends[idx1]\n","                sub_tokens = tokens[start1:end1+1]\n","                sub_labels = labels[start1:end1+1]\n","                val_pos = 0\n","                for i, token in enumerate(sub_tokens):\n","                    if token == 'VAL':\n","                        val_pos = i + 1\n","                        break\n","                sub_tokens = sub_tokens[val_pos:]\n","                sub_labels = sub_labels[val_pos:]\n","\n","                end2 = col_ends[idx2]\n","                new_tokens = []\n","                new_labels = []\n","                for i in range(len(tokens)):\n","                    if start1 <= i <= end1:\n","                        continue\n","                    new_tokens.append(tokens[i])\n","                    new_labels.append(labels[i])\n","                    if i == end2:\n","                        new_tokens += sub_tokens\n","                        new_labels += sub_labels\n","                return new_tokens, new_labels\n","            else:\n","                new_tokens, new_labels = tokens, labels\n","        elif 'drop_col' in op:\n","            col_starts = [i for i in range(len(tokens)) if tokens[i] == 'COL']\n","            col_ends = [0] * len(col_starts)\n","            col_lens = [0] * len(col_starts)\n","            for i, pos in enumerate(col_starts):\n","                if i == len(col_starts) - 1:\n","                    col_lens[i] = len(tokens) - pos\n","                    col_ends[i] = len(tokens) - 1\n","                else:\n","                    col_lens[i] = col_starts[i + 1] - pos\n","                    col_ends[i] = col_starts[i + 1] - 1\n","\n","                if tokens[col_ends[i]] == '[SEP]':\n","                    col_ends[i] -= 1\n","                    col_lens[i] -= 1\n","            candidates = [i for i, le in enumerate(col_lens) if le <= 8]\n","            if len(candidates) > 0:\n","                idx = random.choice(candidates)\n","                start, end = col_starts[idx], col_ends[idx]\n","                new_tokens = tokens[:start] + tokens[end+1:]\n","                new_labels = labels[:start] + labels[end+1:]\n","            else:\n","                new_tokens, new_labels = tokens, labels\n","        else:\n","            new_tokens, new_labels = tokens, labels\n","\n","        return new_tokens, new_labels\n","\n","\n","    def augment_sent(self, text, op='all'):\n","        \"\"\" Performs data augmentation on a classification example.\n","\n","        Similar to augment(tokens, labels) but works for sentences\n","        or sentence-pairs.\n","\n","        Args:\n","            text (str): the input sentence\n","            op (str, optional): a string encoding of the operator to be applied\n","\n","        Returns:\n","            str: the augmented sentence\n","        \"\"\"\n","        # 50% of chance of flipping\n","        if ' [SEP] ' in text and random.randint(0, 1) == 0:\n","            left, right = text.split(' [SEP] ')\n","            text = right + ' [SEP] ' + left\n","\n","        # tokenize the sentence\n","        current = ''\n","        tokens = text.split(' ')\n","\n","        # avoid the special tokens\n","        labels = []\n","        for token in tokens:\n","            if token in ['COL', 'VAL']:\n","                labels.append('HD')\n","            elif token in ['[CLS]', '[SEP]']:\n","                labels.append('<SEP>')\n","            else:\n","                labels.append('O')\n","\n","        if op == 'all':\n","            # RandAugment: https://arxiv.org/pdf/1909.13719.pdf\n","            N = 3\n","            ops = ['del', 'swap', 'drop_col', 'append_col']\n","            for op in random.choices(ops, k=N):\n","                tokens, labels = self.augment(tokens, labels, op=op)\n","        else:\n","            tokens, labels = self.augment(tokens, labels, op=op)\n","        results = ' '.join(tokens)\n","        return results\n","\n","    def sample_span(self, tokens, labels, span_len=3):\n","        candidates = []\n","        for idx, token in enumerate(tokens):\n","            if idx + span_len - 1 < len(labels) and ''.join(labels[idx:idx+span_len]) == 'O'*span_len:\n","                candidates.append((idx, idx+span_len-1))\n","        if len(candidates) <= 0:\n","            return -1, -1\n","        return random.choice(candidates)\n","\n","    def sample_position(self, tokens, labels, tfidf=False):\n","        candidates = []\n","        for idx, token in enumerate(tokens):\n","            if labels[idx] == 'O':\n","                candidates.append(idx)\n","        if len(candidates) <= 0:\n","            return -1\n","        return random.choice(candidates)"],"metadata":{"id":"wx0GVyGmdY8T","executionInfo":{"status":"ok","timestamp":1725696896142,"user_tz":-120,"elapsed":6,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"SdzKDqd6eKxs"}},{"cell_type":"code","source":["class DittoDataset(data.Dataset):\n","    \"\"\"EM dataset\"\"\"\n","\n","    def __init__(self,\n","                 path,\n","                 max_len=256,\n","                 size=None,\n","                 lm='roberta-base',\n","                 da=None):\n","        self.tokenizer = AutoTokenizer.from_pretrained(lm)\n","        self.pairs = []\n","        self.labels = []\n","        self.max_len = max_len\n","        self.size = size\n","\n","        if isinstance(path, list):\n","            lines = path\n","        else:\n","            lines = open(path)\n","\n","        for line in lines:\n","            s1, s2, label = line.strip().split('\\t')\n","            self.pairs.append((s1, s2))\n","            self.labels.append(int(label))\n","\n","        self.pairs = self.pairs[:size]\n","        self.labels = self.labels[:size]\n","        self.da = da\n","        if da is not None:\n","            self.augmenter = Augmenter()\n","        else:\n","            self.augmenter = None\n","\n","\n","    def __len__(self):\n","        \"\"\"Return the size of the dataset.\"\"\"\n","        return len(self.pairs)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"Return a tokenized item of the dataset.\n","\n","        Args:\n","            idx (int): the index of the item\n","\n","        Returns:\n","            List of int: token ID's of the two entities\n","            List of int: token ID's of the two entities augmented (if da is set)\n","            int: the label of the pair (0: unmatch, 1: match)\n","        \"\"\"\n","        left = self.pairs[idx][0]\n","        right = self.pairs[idx][1]\n","\n","        # left + right\n","        x = self.tokenizer.encode(text=left,\n","                                  text_pair=right,\n","                                  max_length=self.max_len,\n","                                  truncation=True)\n","\n","        # augment if da is set\n","        if self.da is not None:\n","            combined = self.augmenter.augment_sent(left + ' [SEP] ' + right, self.da)\n","            left, right = combined.split(' [SEP] ')\n","            x_aug = self.tokenizer.encode(text=left,\n","                                      text_pair=right,\n","                                      max_length=self.max_len,\n","                                      truncation=True)\n","            return x, x_aug, self.labels[idx]\n","        else:\n","            return x, self.labels[idx]\n","\n","\n","    @staticmethod\n","    def pad(batch):\n","        \"\"\"Merge a list of dataset items into a train/test batch\n","        Args:\n","            batch (list of tuple): a list of dataset items\n","\n","        Returns:\n","            LongTensor: x1 of shape (batch_size, seq_len)\n","            LongTensor: x2 of shape (batch_size, seq_len).\n","                        Elements of x1 and x2 are padded to the same length\n","            LongTensor: a batch of labels, (batch_size,)\n","        \"\"\"\n","        if len(batch[0]) == 3:\n","            x1, x2, y = zip(*batch)\n","\n","            maxlen = max([len(x) for x in x1+x2])\n","            x1 = [xi + [0]*(maxlen - len(xi)) for xi in x1]\n","            x2 = [xi + [0]*(maxlen - len(xi)) for xi in x2]\n","            return torch.LongTensor(x1), \\\n","                   torch.LongTensor(x2), \\\n","                   torch.LongTensor(y)\n","        else:\n","            x12, y = zip(*batch)\n","            maxlen = max([len(x) for x in x12])\n","            x12 = [xi + [0]*(maxlen - len(xi)) for xi in x12]\n","            return torch.LongTensor(x12), \\\n","                   torch.LongTensor(y)"],"metadata":{"id":"2zxadONHcTnz","executionInfo":{"status":"ok","timestamp":1725696896142,"user_tz":-120,"elapsed":5,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Summarizer"],"metadata":{"id":"CGp2ae_1dwCl"}},{"cell_type":"code","source":["stopwords = set(stopwords.words('english'))\n","\n","class Summarizer:\n","    \"\"\"To summarize a data entry pair into length up to the max sequence length.\n","\n","    Args:\n","        task_config (Dictionary): the task configuration\n","        lm (string): the language model (bert, albert, or distilbert)\n","\n","    Attributes:\n","        config (Dictionary): the task configuration\n","        tokenizer (Tokenizer): a tokenizer from the huggingface library\n","    \"\"\"\n","    def __init__(self, task_config, lm):\n","        self.config = task_config\n","        self.tokenizer = AutoTokenizer.from_pretrained(lm)\n","        self.len_cache = {}\n","\n","        # build the tfidf index\n","        self.build_index()\n","\n","    def build_index(self):\n","        \"\"\"Build the idf index.\n","\n","        Store the index and vocabulary in self.idf and self.vocab.\n","        \"\"\"\n","        fns = [self.config['trainset'],\n","               self.config['validset'],\n","               self.config['testset']]\n","        content = []\n","        for fn in fns:\n","            with open(fn) as fin:\n","                for line in fin:\n","                    LL = line.split('\\t')\n","                    if len(LL) > 2:\n","                        for entry in LL:\n","                            content.append(entry)\n","\n","        vectorizer = TfidfVectorizer().fit(content)\n","        self.vocab = vectorizer.vocabulary_\n","        self.idf = vectorizer.idf_\n","\n","    def get_len(self, word):\n","        \"\"\"Return the sentence_piece length of a token.\n","        \"\"\"\n","        if word in self.len_cache:\n","            return self.len_cache[word]\n","        length = len(self.tokenizer.tokenize(word))\n","        self.len_cache[word] = length\n","        return length\n","\n","    def transform(self, row, max_len=128):\n","        \"\"\"Summarize one single example.\n","\n","        Only retain tokens of the highest tf-idf\n","\n","        Args:\n","            row (str): a matching example of two data entries and a binary label, separated by tab\n","            max_len (int, optional): the maximum sequence length to be summarized to\n","\n","        Returns:\n","            str: the summarized example\n","        \"\"\"\n","        sentA, sentB, label = row.strip().split('\\t')\n","        res = ''\n","        cnt = Counter()\n","        for sent in [sentA, sentB]:\n","            tokens = sent.split(' ')\n","            for token in tokens:\n","                if token not in ['COL', 'VAL'] and \\\n","                   token not in stopwords:\n","                    if token in self.vocab:\n","                        cnt[token] += self.idf[self.vocab[token]]\n","\n","        for sent in [sentA, sentB]:\n","            token_cnt = Counter(sent.split(' '))\n","            total_len = token_cnt['COL'] + token_cnt['VAL']\n","\n","            subset = Counter()\n","            for token in set(token_cnt.keys()):\n","                subset[token] = cnt[token]\n","            subset = subset.most_common(max_len)\n","\n","            topk_tokens_copy = set([])\n","            for word, _ in subset:\n","                bert_len = self.get_len(word)\n","                if total_len + bert_len > max_len:\n","                    break\n","                total_len += bert_len\n","                topk_tokens_copy.add(word)\n","\n","            num_tokens = 0\n","            for token in sent.split(' '):\n","                if token in ['COL', 'VAL']:\n","                    res += token + ' '\n","                elif token in topk_tokens_copy:\n","                    res += token + ' '\n","                    topk_tokens_copy.remove(token)\n","\n","            res += '\\t'\n","\n","        res += label + '\\n'\n","        return res\n","\n","    def transform_file(self, input_fn, max_len=256, overwrite=False):\n","        \"\"\"Summarize all lines of a tsv file.\n","\n","        Run the summarizer. If the output already exists, just return the file name.\n","\n","        Args:\n","            input_fn (str): the input file name\n","            max_len (int, optional): the max sequence len\n","            overwrite (bool, optional): if true, then overwrite any cached output\n","\n","        Returns:\n","            str: the output file name\n","        \"\"\"\n","        out_fn = input_fn + '.su'\n","        if not os.path.exists(out_fn) or \\\n","           os.stat(out_fn).st_size == 0 or overwrite:\n","            with open(out_fn, 'w') as fout:\n","                for line in open(input_fn):\n","                    fout.write(self.transform(line, max_len=max_len))\n","        return out_fn"],"metadata":{"id":"j_49luCid5fc","executionInfo":{"status":"ok","timestamp":1725696896142,"user_tz":-120,"elapsed":5,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## DK injector"],"metadata":{"id":"7Jz4OjYXfM5R"}},{"cell_type":"code","source":["class DKInjector:\n","    \"\"\"Inject domain knowledge to the data entry pairs.\n","\n","    Attributes:\n","        config: the task configuration\n","        name: the injector name\n","    \"\"\"\n","    def __init__(self, config, name):\n","        self.config = config\n","        self.name = name\n","        self.initialize()\n","\n","    def initialize(self):\n","        \"\"\"Initialize spacy\"\"\"\n","        self.nlp = spacy.load('en_core_web_lg')\n","\n","    def transform_file(self, input_fn, overwrite=False):\n","        \"\"\"Transform all lines of a tsv file.\n","\n","        Run the knowledge injector. If the output already exists, just return the file name.\n","\n","        Args:\n","            input_fn (str): the input file name\n","            overwrite (bool, optional): if true, then overwrite any cached output\n","\n","        Returns:\n","            str: the output file name\n","        \"\"\"\n","        out_fn = input_fn + '.dk'\n","        if not os.path.exists(out_fn) or \\\n","            os.stat(out_fn).st_size == 0 or overwrite:\n","\n","            with open(out_fn, 'w') as fout:\n","                for line in open(input_fn):\n","                    LL = line.split('\\t')\n","                    if len(LL) == 3:\n","                        entry0 = self.transform(LL[0])\n","                        entry1 = self.transform(LL[1])\n","                        fout.write(entry0 + '\\t' + entry1 + '\\t' + LL[2])\n","        return out_fn\n","\n","    def transform(self, entry):\n","        \"\"\"Transform a data entry.\n","\n","        Use NER to regconize the product-related named entities and\n","        mark them in the sequence. Normalize the numbers into the same format.\n","\n","        Args:\n","            entry (str): the serialized data entry\n","\n","        Returns:\n","            str: the transformed entry\n","        \"\"\"\n","        res = ''\n","        doc = self.nlp(entry, disable=['tagger', 'parser'])\n","        ents = doc.ents\n","        start_indices = {}\n","        end_indices = {}\n","\n","        for ent in ents:\n","            start, end, label = ent.start, ent.end, ent.label_\n","            if label in ['PERSON', 'ORG', 'LOC', 'PRODUCT', 'DATE', 'QUANTITY', 'TIME']:\n","                start_indices[start] = label\n","                end_indices[end] = label\n","\n","        for idx, token in enumerate(doc):\n","            if idx in start_indices:\n","                res += start_indices[idx] + ' '\n","\n","            # normalizing the numbers\n","            if token.like_num:\n","                try:\n","                    val = float(token.text)\n","                    if val == round(val):\n","                        res += '%d ' % (int(val))\n","                    else:\n","                        res += '%.2f ' % (val)\n","                except:\n","                    res += token.text + ' '\n","            elif len(token.text) >= 7 and \\\n","                 any([ch.isdigit() for ch in token.text]):\n","                res += 'ID ' + token.text + ' '\n","            else:\n","                res += token.text + ' '\n","        return res.strip()"],"metadata":{"id":"RiNwdhtPfR0F","executionInfo":{"status":"ok","timestamp":1725696896142,"user_tz":-120,"elapsed":5,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"n5APNNk2QbB0"}},{"cell_type":"code","source":["class DittoModel(nn.Module):\n","\n","    def __init__(self, device='cuda', lm='roberta-base', alpha_aug=0.8):\n","        super().__init__()\n","\n","        self.bert = AutoModel.from_pretrained(lm)\n","        self.device = device\n","        self.alpha_aug = alpha_aug\n","\n","        # linear layer\n","        hidden_size = self.bert.config.hidden_size\n","        self.fc = torch.nn.Linear(hidden_size, 2)\n","\n","\n","    def forward(self, x1, x2=None):\n","        \"\"\"Encode the left, right, and the concatenation of left+right.\n","\n","        Args:\n","            x1 (LongTensor): a batch of ID's\n","            x2 (LongTensor, optional): a batch of ID's (augmented)\n","\n","        Returns:\n","            Tensor: binary prediction\n","        \"\"\"\n","        x1 = x1.to(self.device) # (batch_size, seq_len)\n","\n","        if x2 is not None:\n","            # MixDA\n","            x2 = x2.to(self.device) # (batch_size, seq_len)\n","            enc = self.bert(torch.cat((x1, x2)))[0][:, 0, :]\n","            batch_size = len(x1)\n","            enc1 = enc[:batch_size] # (batch_size, emb_size)\n","            enc2 = enc[batch_size:] # (batch_size, emb_size)\n","\n","            aug_lam = np.random.beta(self.alpha_aug, self.alpha_aug)\n","            enc = enc1 * aug_lam + enc2 * (1.0 - aug_lam)\n","        else:\n","            enc = self.bert(x1)[0][:, 0, :]\n","\n","        return self.fc(enc)"],"metadata":{"id":"1gPojIAgPnkE","executionInfo":{"status":"ok","timestamp":1725696896142,"user_tz":-120,"elapsed":4,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Train utils"],"metadata":{"id":"5WR0d9D3R_xp"}},{"cell_type":"code","source":["def evaluate(model, iterator, threshold=None):\n","    \"\"\"Evaluate a model on a validation/test dataset\n","\n","    Args:\n","        model (DMModel): the EM model\n","        iterator (Iterator): the valid/test dataset iterator\n","        threshold (float, optional): the threshold on the 0-class\n","\n","    Returns:\n","        float: the F1 score\n","        float (optional): if threshold is not provided, the threshold\n","            value that gives the optimal F1\n","    \"\"\"\n","    all_p = []\n","    all_y = []\n","    all_probs = []\n","    with torch.no_grad():\n","        for batch in iterator:\n","            x, y = batch\n","            logits = model(x)\n","            probs = logits.softmax(dim=1)[:, 1]\n","            all_probs += probs.cpu().numpy().tolist()\n","            all_y += y.cpu().numpy().tolist()\n","\n","    if threshold is not None:\n","        pred = [1 if p > threshold else 0 for p in all_probs]\n","        f1 = metrics.f1_score(all_y, pred)\n","        return f1\n","    else:\n","        best_th = 0.5\n","        f1 = 0.0\n","\n","        for th in np.arange(0.0, 1.0, 0.05):\n","            pred = [1 if p > th else 0 for p in all_probs]\n","            new_f1 = metrics.f1_score(all_y, pred)\n","            if new_f1 > f1:\n","                f1 = new_f1\n","                best_th = th\n","\n","        return f1, best_th\n","\n","\n","def train_step(train_iter, model, optimizer, scheduler, hp):\n","    \"\"\"Perform a single training step\n","\n","    Args:\n","        train_iter (Iterator): the train data loader\n","        model (DMModel): the model\n","        optimizer (Optimizer): the optimizer (Adam or AdamW)\n","        scheduler (LRScheduler): learning rate scheduler\n","        hp (Namespace): other hyper-parameters (e.g., fp16)\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    criterion = nn.CrossEntropyLoss()\n","\n","    for i, batch in enumerate(train_iter):\n","        optimizer.zero_grad()\n","\n","        if len(batch) == 2:\n","            x, y = batch\n","            prediction = model(x)\n","        else:\n","            x1, x2, y = batch\n","            prediction = model(x1, x2)\n","\n","        loss = criterion(prediction, y.to(model.device))\n","\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","        if i % 10 == 0: # monitoring\n","            print(f\"step: {i}, loss: {loss.item()}\")\n","        del loss\n","\n","\n","def train(trainset, validset, testset, hp):\n","    \"\"\"Train and evaluate the model\n","\n","    Args:\n","        trainset (DittoDataset): the training set\n","        validset (DittoDataset): the validation set\n","        testset (DittoDataset): the test set\n","        hp (Namespace): Hyper-parameters (e.g., batch_size,\n","                        learning rate)\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    padder = trainset.pad\n","    # create the DataLoaders\n","    train_iter = data.DataLoader(dataset=trainset,\n","                                 batch_size=args['batch_size'],\n","                                 shuffle=True,\n","                                 num_workers=0,\n","                                 collate_fn=padder)\n","    valid_iter = data.DataLoader(dataset=validset,\n","                                 batch_size=args['batch_size'],\n","                                 shuffle=False,\n","                                 num_workers=0,\n","                                 collate_fn=padder)\n","    test_iter = data.DataLoader(dataset=testset,\n","                                 batch_size=args['batch_size'],\n","                                 shuffle=False,\n","                                 num_workers=0,\n","                                 collate_fn=padder)\n","\n","    # initialize model, optimizer, and LR scheduler\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model = DittoModel(device=device,\n","                       lm=args['lm'],\n","                       alpha_aug=args['alpha_aug'])\n","    model = model.cuda()\n","    optimizer = AdamW(model.parameters(), lr=args['lr'])\n","\n","    num_steps = (len(trainset) // args['batch_size']) * args['n_epochs']\n","    scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                                num_warmup_steps=0,\n","                                                num_training_steps=num_steps)\n","\n","    best_dev_f1 = best_test_f1 = 0.0\n","    for epoch in range(1, args['n_epochs']+1):\n","        # train\n","        model.train()\n","        train_step(train_iter, model, optimizer, scheduler, hp)\n","\n","        # eval\n","        model.eval()\n","        dev_f1, th = evaluate(model, valid_iter)\n","        test_f1 = evaluate(model, test_iter, threshold=th)\n","\n","        if dev_f1 > best_dev_f1:\n","            best_dev_f1 = dev_f1\n","            best_test_f1 = test_f1\n","            if args['save_model']:\n","                # save the checkpoints for each component\n","                ckpt_path = os.path.join('model.pt')\n","                ckpt = {'model': model.state_dict(),\n","                        'optimizer': optimizer.state_dict(),\n","                        'scheduler': scheduler.state_dict(),\n","                        'epoch': epoch}\n","                torch.save(ckpt, ckpt_path)\n","\n","        print(f\"epoch {epoch}: f1={dev_f1}\")"],"metadata":{"id":"txoAaokHSBwr","executionInfo":{"status":"ok","timestamp":1725696896142,"user_tz":-120,"elapsed":4,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"xigfMvzgQq0-"}},{"cell_type":"code","source":["args = {\n","    \"task\": \"Structured/Beer\",\n","    \"run_id\": 123,\n","    \"batch_size\": 64,\n","    \"max_len\": 256,\n","    \"lr\": 3e-5,\n","    \"n_epochs\": 20,\n","    \"finetuning\": True,\n","    \"save_model\": True,\n","    \"logdir\": \"checkpoints/\",\n","    \"lm\": \"roberta-base\",\n","    \"da\": 'drop_col',\n","    \"alpha_aug\": 0.8,\n","    \"dk\": None,\n","    \"summarize\": False,\n","    \"size\": None\n","}\n","\n","# set seeds\n","seed = args['run_id']\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","trainset = 'train.txt'\n","validset = 'valid.txt'\n","testset = 'test.txt'\n","config = {\n","    'trainset': trainset,\n","    'validset': validset,\n","    'testset': testset,\n","}\n","\n","# summarize the sequences up to the max sequence length\n","if args['summarize']:\n","    summarizer = Summarizer(config, lm=args['lm'])\n","    trainset = summarizer.transform_file(trainset, max_len=args['max_len'])\n","    validset = summarizer.transform_file(validset, max_len=args['max_len'])\n","    testset = summarizer.transform_file(testset, max_len=args['max_len'])\n","\n","if args['dk'] is not None:\n","    injector = DKInjector(config, args['dk'])\n","\n","    trainset = injector.transform_file(trainset)\n","    validset = injector.transform_file(validset)\n","    testset = injector.transform_file(testset)\n","\n","# load train/dev/test sets\n","train_dataset = DittoDataset(trainset,\n","                             lm=args['lm'],\n","                             max_len=args['max_len'],\n","                             size=args['size'],\n","                             da=args['da'])\n","valid_dataset = DittoDataset(validset, lm=args['lm'])\n","test_dataset = DittoDataset(testset, lm=args['lm'])\n","\n","# train and evaluate the model\n","train(train_dataset,\n","      valid_dataset,\n","      test_dataset,\n","      args)"],"metadata":{"id":"GZH4z16ZQsf4","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5e7969f59f5746daa2ed74c09268f94e","4b383c3de3c74d9c8c98e9561ca3d079","32b8af14ce7e4a30a976b1fe413dd388","37d2ec36c67249b5ad43349cc7f5a130","4e659bfdba154fd99fa20b85130009b3","ad860d64d433496994eb8e04136ac30b","2b6ac2e3ccf24eef8d1245350a8c42b3","507153608f0248c1beef89d551469e75","4825b967604c428ead396a5f354a484b","607195a85ae34c169cd4917b9374709f","0e1396ebab0d45a89f7ead8ba4a63173","f0a10a02037545f0beeb36f6a2d52a40","4e711ec4c06b467caaed45be969c6df7","60357971436b4a6f956ded7b2d1c8606","fc6c623ca0b44310bdce0ae5855b9b40","b2c33b8464ed4eaf86395e229714e870","c896e80432d74c1ca509aaf43c23a906","cb1089a94f8c4882b9826450e3c9fb98","17c4b6bc8dd443afbe9c9544b4115e87","31a39265997643159e46153542ecbfac","bff397b6a4574bd08602f0f98ab674c6","61249fef881e457e9956446e7e631921","836c6d9e978a4937848ec65f94428cdf","b845879cef174924a9dd69fecc159a8d","d885f524b0dd49bd9344e3eb530c3e8c","67eb34c980e14b909a2acf90440162a9","ccce76cf7d484b72ab90c7f9084c21fc","7e8f940731f74834b7e5a843df14e40a","7baf31fe312c41f1a0207756c761defa","772ed413826d42889de6b21d845197e3","8f04503ba0124f81a90a7502f7f0d16a","0a9af53757354c0da7867cd46a2558f5","a02a46b9054b4f04aa2994b0ae505fd7","ae5439e19ef246a0a86ad23ab70f02c9","ad1ba7c81ee5441ebd3041859f2e1324","8657afd576864fd8ab62657304c6417e","38f8ea4b335d4343a49ad014550030ed","c935db4ad072478f8e29adf25f595e36","ec2bb75474c6427fa06bb271517f71dc","95fdb6969bf54bf3a8c0e65b3d2b513c","59cad8b171d94f8f84ad1b008bdd2c72","e61f8d76b9e2436398f17d572671a2e3","b53f241dcf23469086b1401f0f3acbd4","a0ea06079dea4a59ab2e20f27ec9edce","a492b079d703422887221481d05835a2","3cc59c75786a437f9ede911ae9665176","8f5a7327f4b845989fe1444a74214253","f94ab14be5c94f8c8814234bb8150855","8243793df3d54aa0b0f07ceea5d6412d","2bcb4b2f29b34d2ca3bcea957192f848","590849c5e4b64f53841a74f826bc45e7","2ba881b4d82e48cf86f87ec8bc631d12","bd3e88f23cf6434fa31356ac59d216ad","c81b1cc153314e72babd5a75353d8c27","0ddbb3f175104daf83cca51cf8035fec","29426945a33840a28be61c5d8503d049","a614de527d6a412da4d0435ad5183060","eda78502c19949768438592b02e2cea9","3c581cecb60741548be61d1180a2af2c","4796990006a24eb4a6599e40de17771b","13764a4fb9794f2dbf7dcbbb774ec26d","6f7eed13ab2645eaa35956da2bec9515","e9b3fa83df0f49129a8546068254237c","cb670a6f14f44e21927d9fef2964ded3","7811fa6f385247c48b1cc9958a1d8f0f","4a136676a6194e5ea673ecf303e86cea"]},"executionInfo":{"status":"ok","timestamp":1725697208098,"user_tz":-120,"elapsed":311960,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}},"outputId":"06a38f0f-cea7-47fe-f335-fcd4c7f70e4a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e7969f59f5746daa2ed74c09268f94e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a10a02037545f0beeb36f6a2d52a40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"836c6d9e978a4937848ec65f94428cdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae5439e19ef246a0a86ad23ab70f02c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a492b079d703422887221481d05835a2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29426945a33840a28be61c5d8503d049"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["step: 0, loss: 0.6497491002082825\n","epoch 1: f1=0.2666666666666667\n","step: 0, loss: 0.39931249618530273\n","epoch 2: f1=0.27184466019417475\n","step: 0, loss: 0.4042988717556\n","epoch 3: f1=0.2692307692307693\n","step: 0, loss: 0.43629908561706543\n","epoch 4: f1=0.3773584905660377\n","step: 0, loss: 0.3302553594112396\n","epoch 5: f1=0.40625\n","step: 0, loss: 0.2828435003757477\n","epoch 6: f1=0.4444444444444445\n","step: 0, loss: 0.40554261207580566\n","epoch 7: f1=0.45454545454545453\n","step: 0, loss: 0.42321130633354187\n","epoch 8: f1=0.5777777777777778\n","step: 0, loss: 0.41000962257385254\n","epoch 9: f1=0.689655172413793\n","step: 0, loss: 0.2845877408981323\n","epoch 10: f1=0.7878787878787878\n","step: 0, loss: 0.203620046377182\n","epoch 11: f1=0.7741935483870968\n","step: 0, loss: 0.32986846566200256\n","epoch 12: f1=0.896551724137931\n","step: 0, loss: 0.12400054931640625\n","epoch 13: f1=0.896551724137931\n","step: 0, loss: 0.24103820323944092\n","epoch 14: f1=0.9032258064516129\n","step: 0, loss: 0.047060687094926834\n","epoch 15: f1=0.9032258064516129\n","step: 0, loss: 0.12831860780715942\n","epoch 16: f1=0.9333333333333333\n","step: 0, loss: 0.1135585606098175\n","epoch 17: f1=0.9333333333333333\n","step: 0, loss: 0.0557611919939518\n","epoch 18: f1=0.9333333333333333\n","step: 0, loss: 0.1345994770526886\n","epoch 19: f1=0.9333333333333333\n","step: 0, loss: 0.17738747596740723\n","epoch 20: f1=0.9333333333333333\n"]}]},{"cell_type":"markdown","source":["# Inference utils"],"metadata":{"id":"8ql76O6gg5il"}},{"cell_type":"code","source":["def to_str(ent1, ent2, summarizer=None, max_len=256, dk_injector=None):\n","    \"\"\"Serialize a pair of data entries\n","\n","    Args:\n","        ent1 (Dictionary): the 1st data entry\n","        ent2 (Dictionary): the 2nd data entry\n","        summarizer (Summarizer, optional): the summarization module\n","        max_len (int, optional): the max sequence length\n","        dk_injector (DKInjector, optional): the domain-knowledge injector\n","\n","    Returns:\n","        string: the serialized version\n","    \"\"\"\n","    content = ''\n","    for ent in [ent1, ent2]:\n","        if isinstance(ent, str):\n","            content += ent\n","        else:\n","            for attr in ent.keys():\n","                content += 'COL %s VAL %s ' % (attr, ent[attr])\n","        content += '\\t'\n","\n","    content += '0'\n","\n","    if summarizer is not None:\n","        content = summarizer.transform(content, max_len=max_len)\n","\n","    new_ent1, new_ent2, _ = content.split('\\t')\n","    if dk_injector is not None:\n","        new_ent1 = dk_injector.transform(new_ent1)\n","        new_ent2 = dk_injector.transform(new_ent2)\n","\n","    return new_ent1 + '\\t' + new_ent2 + '\\t0'\n","\n","def classify(sentence_pairs, model,\n","             lm='distilbert',\n","             max_len=256,\n","             threshold=None):\n","    \"\"\"Apply the MRPC model.\n","\n","    Args:\n","        sentence_pairs (list of str): the sequence pairs\n","        model (MultiTaskNet): the model in pytorch\n","        max_len (int, optional): the max sequence length\n","        threshold (float, optional): the threshold of the 0's class\n","\n","    Returns:\n","        list of float: the scores of the pairs\n","    \"\"\"\n","    inputs = sentence_pairs\n","    # print('max_len =', max_len)\n","    dataset = DittoDataset(inputs,\n","                           max_len=max_len,\n","                           lm=lm)\n","    # print(dataset[0])\n","    iterator = data.DataLoader(dataset=dataset,\n","                               batch_size=len(dataset),\n","                               shuffle=False,\n","                               num_workers=0,\n","                               collate_fn=DittoDataset.pad)\n","\n","    # prediction\n","    all_probs = []\n","    all_logits = []\n","    with torch.no_grad():\n","        # print('Classification')\n","        for i, batch in enumerate(iterator):\n","            x, _ = batch\n","            logits = model(x)\n","            probs = logits.softmax(dim=1)[:, 1]\n","            all_probs += probs.cpu().numpy().tolist()\n","            all_logits += logits.cpu().numpy().tolist()\n","\n","    if threshold is None:\n","        threshold = 0.5\n","\n","    pred = [1 if p > threshold else 0 for p in all_probs]\n","    return pred, all_logits\n","\n","def predict(input_path, output_path, config,\n","            model,\n","            batch_size=1024,\n","            summarizer=None,\n","            lm='distilbert',\n","            max_len=256,\n","            dk_injector=None,\n","            threshold=None):\n","    \"\"\"Run the model over the input file containing the candidate entry pairs\n","\n","    Args:\n","        input_path (str): the input file path\n","        output_path (str): the output file path\n","        config (Dictionary): task configuration\n","        model (DittoModel): the model for prediction\n","        batch_size (int): the batch size\n","        summarizer (Summarizer, optional): the summarization module\n","        max_len (int, optional): the max sequence length\n","        dk_injector (DKInjector, optional): the domain-knowledge injector\n","        threshold (float, optional): the threshold of the 0's class\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    pairs = []\n","\n","    def process_batch(rows, pairs, writer):\n","        predictions, logits = classify(pairs, model, lm=lm,\n","                                       max_len=max_len,\n","                                       threshold=threshold)\n","        # try:\n","        #     predictions, logits = classify(pairs, model, lm=lm,\n","        #                                    max_len=max_len,\n","        #                                    threshold=threshold)\n","        # except:\n","        #     # ignore the whole batch\n","        #     return\n","        scores = softmax(logits, axis=1)\n","        for row, pred, score in zip(rows, predictions, scores):\n","            output = {'left': row[0], 'right': row[1],\n","                'match': pred,\n","                'match_confidence': score[int(pred)]}\n","            writer.write(output)\n","\n","    # input_path can also be train/valid/test.txt\n","    # convert to jsonlines\n","    if '.txt' in input_path:\n","        with jsonlines.open(input_path + '.jsonl', mode='w') as writer:\n","            for line in open(input_path):\n","                writer.write(line.split('\\t')[:2])\n","        input_path += '.jsonl'\n","\n","    # batch processing\n","    start_time = time.time()\n","    with jsonlines.open(input_path) as reader,\\\n","         jsonlines.open(output_path, mode='w') as writer:\n","        pairs = []\n","        rows = []\n","        for idx, row in tqdm(enumerate(reader)):\n","            pairs.append(to_str(row[0], row[1], summarizer, max_len, dk_injector))\n","            rows.append(row)\n","            if len(pairs) == batch_size:\n","                process_batch(rows, pairs, writer)\n","                pairs.clear()\n","                rows.clear()\n","\n","        if len(pairs) > 0:\n","            process_batch(rows, pairs, writer)\n","\n","\n","def tune_threshold(config, model, hp):\n","    \"\"\"Tune the prediction threshold for a given model on a validation set\"\"\"\n","    validset = config['validset']\n","\n","    # summarize the sequences up to the max sequence length\n","    summarizer = injector = None\n","    if hp[\"summarize\"]:\n","        summarizer = Summarizer(config, lm=hp[\"lm\"])\n","        validset = summarizer.transform_file(validset, max_len=hp[\"max_len\"], overwrite=True)\n","\n","    if hp[\"dk\"] is not None:\n","        injector = DKInjector(config, hp[\"dk\"])\n","\n","        validset = injector.transform_file(validset)\n","\n","    # load dev sets\n","    valid_dataset = DittoDataset(validset,\n","                                 max_len=hp[\"max_len\"],\n","                                 lm=hp[\"lm\"])\n","\n","    valid_iter = data.DataLoader(dataset=valid_dataset,\n","                                 batch_size=64,\n","                                 shuffle=False,\n","                                 num_workers=0,\n","                                 collate_fn=DittoDataset.pad)\n","\n","    f1, th = evaluate(model, valid_iter, threshold=None)\n","\n","    return th\n","\n","\n","\n","def load_model(lm, checkpoint='model.pt'):\n","    \"\"\"Load a model for a specific task.\n","\n","    Args:\n","        path (str): the path of the checkpoint directory\n","        lm (str): the language model\n","        use_gpu (boolean): whether to use gpu\n","        fp16 (boolean, optional): whether to use fp16\n","\n","    Returns:\n","        the model\n","    \"\"\"\n","    # load model\n","    if not os.path.exists(checkpoint):\n","        raise ValueError(f\"Model not found at: {checkpoint}\")\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    model = DittoModel(device=device, lm=lm)\n","\n","    saved_state = torch.load(\n","        checkpoint, weights_only=True,\n","        map_location=lambda storage, loc: storage)\n","    model.load_state_dict(saved_state['model'])\n","    model = model.to(device)\n","\n","    return model"],"metadata":{"id":"-mFiksvBg601","executionInfo":{"status":"ok","timestamp":1725697208098,"user_tz":-120,"elapsed":11,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Inference"],"metadata":{"id":"BqDg0J7EZC70"}},{"cell_type":"code","source":["args = {\n","    \"task\": \"Structured/Beer\",\n","    \"input_path\": \"test.txt\",\n","    \"output_path\": \"output_small.jsonl\",\n","    \"run_id\": 123,\n","    \"batch_size\": 64,\n","    \"max_len\": 256,\n","    \"lm\": \"roberta-base\",\n","    \"dk\": None,\n","    \"summarize\": False\n","}\n","\n","# set seeds\n","seed = args['run_id']\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","trainset = 'train.txt'\n","validset = 'valid.txt'\n","testset = 'test.txt'\n","config = {\n","    'trainset': trainset,\n","    'validset': validset,\n","    'testset': testset,\n","}\n","\n","model = load_model(args[\"lm\"])\n","\n","summarizer = dk_injector = None\n","if args[\"summarize\"]:\n","    summarizer = Summarizer(config, args[\"lm\"])\n","\n","if args[\"dk\"] is not None:\n","    dk_injector = DKInjector(config, args[\"dk\"])\n","\n","# tune threshold\n","threshold = tune_threshold(config, model, args)\n","\n","# run prediction\n","print(f\"Threshold: {threshold}\")\n","predict(\n","    args[\"input_path\"], args[\"output_path\"], config, model,\n","    summarizer=summarizer, max_len=args[\"max_len\"],\n","    lm=args[\"lm\"], dk_injector=dk_injector,\n","    threshold=threshold\n",")\n","\n","predicts = []\n","with jsonlines.open(args[\"output_path\"], mode=\"r\") as reader:\n","    for line in reader:\n","        predicts.append(int(line['match']))\n","\n","labels = []\n","with open(args[\"input_path\"]) as fin:\n","    for line in fin:\n","        labels.append(int(line.split('\\t')[-1]))\n","\n","f1 = sklearn.metrics.f1_score(labels, predicts)\n","print(\"Test f1 =\", f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6dTCjdewZEPl","executionInfo":{"status":"ok","timestamp":1725697214120,"user_tz":-120,"elapsed":6025,"user":{"displayName":"matteo paganelli","userId":"03619350285854014635"}},"outputId":"ef334117-0840-431e-de36-8dcdcaa649f2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Threshold: 0.30000000000000004\n"]},{"output_type":"stream","name":"stderr","text":["91it [00:00, 59516.87it/s]\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Test f1 = 0.7368421052631579\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6NgOkInBemCr"},"execution_count":null,"outputs":[]}]}